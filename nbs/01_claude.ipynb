{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install anthropic --quiet\n",
    "# !pip install pillow --quiet\n",
    "# !pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "# import src key\n",
    "from src.key import claude_api_key\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=claude_api_key\n",
    ")\n",
    "\n",
    "model=\"claude-3-sonnet-20240229\"\n",
    "small_model=\"claude-3-haiku-20240307\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Request a response from a conversation with Claude.\n",
    "message = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello!\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you describe LLMs to me?\"}\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Put words in Claude's mouth: combine role assistant and maximum tokens to get simple short answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Put words in Claude's mouth: combine role assistant and maximum tokens to get simple short answers.\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is latin for Ant? (A) Apoidea, (B) Rhopalocera, (C) Formicidae\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The answer is (\"}\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, system='', prefill=''):\n",
    "    message = client.messages.create(\n",
    "        model=small_model,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt},\n",
    "          {\"role\": \"assistant\", \"content\": prefill}\n",
    "        ],\n",
    "        system=system\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "# First input variable\n",
    "EMAIL = \"Hi Zack, just pinging you for a quick update on that prompt you were supposed to write.\"\n",
    "\n",
    "# Second input variable\n",
    "ADJECTIVE = \"olde english\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hey Claude. Here is an email: {EMAIL}. Make this email more {ADJECTIVE}. Write the new version in <{ADJECTIVE}_email> XML tags.\"\n",
    "\n",
    "# Prefill for Claude's response (now as an f-string with a variable)\n",
    "PREFILL = f\"<{ADJECTIVE}_email>\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image with questions. for more https://docs.anthropic.com/en/docs/build-with-claude/vision - recommend resizing images before uploading# \n",
    "import base64\n",
    "import httpx\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
    "image_media_type = \"image/jpeg\"\n",
    "image_data = base64.standard_b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image_media_type,\n",
    "                        \"data\": image_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"how many ant in this image\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(message.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add 2 image and find the difference.\n",
    "# https://docs.anthropic.com/en/docs/build-with-claude/vision#example-multiple-images\n",
    "\n",
    "import base64\n",
    "import httpx\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def resize_image(url, max_size=512):\n",
    "    # Download image\n",
    "    response = httpx.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    # Calculate new dimensions maintaining aspect ratio\n",
    "    ratio = min(max_size/img.width, max_size/img.height)\n",
    "    new_size = (int(img.width * ratio), int(img.height * ratio))\n",
    "    \n",
    "    # Resize image\n",
    "    img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Convert back to bytes\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"JPEG\")\n",
    "    return buffer.getvalue()\n",
    "\n",
    "# Resize and encode first image\n",
    "image1_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
    "image1_media_type = \"image/jpeg\"\n",
    "image1_data = base64.standard_b64encode(resize_image(image1_url)).decode(\"utf-8\")\n",
    "\n",
    "# Resize and encode second image\n",
    "image2_url = \"https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg\"\n",
    "image2_media_type = \"image/jpeg\"\n",
    "image2_data = base64.standard_b64encode(resize_image(image2_url)).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# show image in 2 figures\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(Image.open(BytesIO(base64.b64decode(image1_data))))\n",
    "ax[1].imshow(Image.open(BytesIO(base64.b64decode(image2_data))))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Image 1:\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image1_media_type,\n",
    "                        \"data\": image1_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Image 2:\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image2_media_type,\n",
    "                        \"data\": image2_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"How are these images different?\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Learn cookbook: format output https://github.com/anthropics/anthropic-cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Translate hello to French. Respond with a single word\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word, language):\n",
    "  response = client.messages.create(\n",
    "      model=\"claude-3-opus-20240229\",\n",
    "      max_tokens=1000,\n",
    "      messages=[\n",
    "          {\"role\": \"user\", \"content\": f\"Translate the word {word} into {language}.  Only respond with the translated word, nothing else\"}\n",
    "      ]\n",
    "  )\n",
    "  return response.content[0].text\n",
    "\n",
    "print(translate(\"hello\", \"French\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=500,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Unpopular opinion: Pickles are disgusting. Don't @ me\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"NEGATIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think my love for pickles might be getting out of hand. I just bought a pickle-shaped pool float\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"POSITIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"Seriously why would anyone ever eat a pickle?  Those things are nasty!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"NEGATIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"Just tried the new spicy pickles from @PickleCo, and my taste buds are doing a happy dance! 🌶️🥒 #pickleslove #spicyfood\"},\n",
    "    ]\n",
    ")\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    system=\"You are a helpful foreign language tutor that always responds in French.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hey there, how are you?!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(topic, num_questions=3):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=500,\n",
    "        system=f\"You are an expert on {topic}. Generate thought-provoking questions about this topic.\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Generate {num_questions} questions about {topic} as a numbered list.\"}\n",
    "        ],\n",
    "        stop_sequences=[f\"{num_questions+1}.\"]\n",
    "    )\n",
    "    print(response.content[0].text)\n",
    "\n",
    "generate_questions(\"Ants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8. Temperature: temperature is a parameter in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, system=''):\n",
    "    message = client.messages.create(\n",
    "        model=small_model,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        system=system\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Role prompt: assign role in the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Prompt template or input template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cow\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"I will tell you the name of an animal. Please respond with the noise that animal makes. {ANIMAL}\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Yo Claude. {EMAIL} <----- Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "SENTENCES = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\"Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "{SENTENCES}\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. XML tags: use specifically XML tags as separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#example-legal-contract-analysis\n",
    "user_prompt = \"\"\"You’re a financial analyst at AcmeCorp. Generate a Q2 financial report for our investors.\n",
    "\n",
    "AcmeCorp is a B2B SaaS company. Our investors value transparency and actionable insights.\n",
    "\n",
    "Use this data for your report:<data>{{SPREADSHEET_DATA}}</data>\n",
    "\n",
    "<instructions>\n",
    "1. Include sections: Revenue Growth, Profit Margins, Cash Flow.\n",
    "2. Highlight strengths and areas for improvement.\n",
    "</instructions>\n",
    "\n",
    "Make your tone concise and professional. Follow this structure:\n",
    "<formatting_example>{{Q1_REPORT}}</formatting_example>\"\"\"\n",
    "\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Long context tips:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpompt = \"\"\"You are an AI physician's assistant. Your task is to help doctors diagnose possible patient illnesses.\n",
    "\n",
    "<documents>\n",
    "  <document index=\"1\">\n",
    "    <source>patient_symptoms.txt</source>\n",
    "    <document_content>\n",
    "      {{PATIENT_SYMPTOMS}}\n",
    "    </document_content>\n",
    "  </document>\n",
    "  <document index=\"2\">\n",
    "    <source>patient_records.txt</source>\n",
    "    <document_content>\n",
    "      {{PATIENT_RECORDS}}\n",
    "    </document_content>\n",
    "  </document>\n",
    "  <document index=\"3\">\n",
    "    <source>patient01_appt_history.txt</source>\n",
    "    <document_content>\n",
    "      {{PATIENT01_APPOINTMENT_HISTORY}}\n",
    "    </document_content>\n",
    "  </document>\n",
    "</documents>\n",
    "\n",
    "Find quotes from the patient records and appointment history that are relevant to diagnosing the patient's reported symptoms. Place these in <quotes> tags. Then, based on these quotes, list all information that would help the doctor diagnose the patient's symptoms. Place your diagnostic information in <info> tags.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"{\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Think step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in  and  XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in tags, then give your answer.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Avoid hallucinations: give Claude an out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Who is the heaviest hippo of all time? Only answer if you know the answer with certainty.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. it's best practice to have the question at the bottom after any text or document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. [Complex prompt from scatch](https://github.com/anthropics/courses/blob/master/prompt_engineering_interactive_tutorial/AmazonBedrock/anthropic/09_Complex_Prompts_from_Scratch.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## INPUT VARIABLES ########################################\n",
    "\n",
    "# First input variable - the conversation history (this can also be added as preceding `user` and `assistant` messages in the API call)\n",
    "HISTORY = \"\"\"Customer: Give me two possible careers for sociology majors.\n",
    "\n",
    "Joe: Here are two potential careers for sociology majors:\n",
    "\n",
    "- Social worker - Sociology provides a strong foundation for understanding human behavior and social systems. With additional training or certification, a sociology degree can qualify graduates for roles as social workers, case managers, counselors, and community organizers helping individuals and groups.\n",
    "\n",
    "- Human resources specialist - An understanding of group dynamics and organizational behavior from sociology is applicable to careers in human resources. Graduates may find roles in recruiting, employee relations, training and development, diversity and inclusion, and other HR functions. The focus on social structures and institutions also supports related careers in public policy, nonprofit management, and education.\"\"\"\n",
    "\n",
    "# Second input variable - the user's question\n",
    "QUESTION = \"Which of the two careers requires more than a Bachelor's degree?\"\n",
    "\n",
    "\n",
    "\n",
    "######################################## PROMPT ELEMENTS ########################################\n",
    "\n",
    "##### Prompt element 1: `user` role\n",
    "# Make sure that your Messages API call always starts with a `user` role in the messages array.\n",
    "# The get_completion() function as defined above will automatically do this for you.\n",
    "\n",
    "##### Prompt element 2: Task context\n",
    "# Give Claude context about the role it should take on or what goals and overarching tasks you want it to undertake with the prompt.\n",
    "# It's best to put context early in the body of the prompt.\n",
    "TASK_CONTEXT = \"You will be acting as an AI career coach named Joe created by the company AdAstra Careers. Your goal is to give career advice to users. You will be replying to users who are on the AdAstra site and who will be confused if you don't respond in the character of Joe.\"\n",
    "\n",
    "##### Prompt element 3: Tone context\n",
    "# If important to the interaction, tell Claude what tone it should use.\n",
    "# This element may not be necessary depending on the task.\n",
    "TONE_CONTEXT = \"You should maintain a friendly customer service tone.\"\n",
    "\n",
    "##### Prompt element 4: Detailed task description and rules\n",
    "# Expand on the specific tasks you want Claude to do, as well as any rules that Claude might have to follow.\n",
    "# This is also where you can give Claude an \"out\" if it doesn't have an answer or doesn't know.\n",
    "# It's ideal to show this description and rules to a friend to make sure it is laid out logically and that any ambiguous words are clearly defined.\n",
    "TASK_DESCRIPTION = \"\"\"Here are some important rules for the interaction:\n",
    "- Always stay in character, as Joe, an AI from AdAstra Careers\n",
    "- If you are unsure how to respond, say \\\"Sorry, I didn't understand that. Could you rephrase your question?\\\"\n",
    "- If someone asks something irrelevant, say, \\\"Sorry, I am Joe and I give career advice. Do you have a career question today I can help you with?\\\"\"\"\"\n",
    "\n",
    "##### Prompt element 5: Examples\n",
    "# Provide Claude with at least one example of an ideal response that it can emulate. Encase this in  XML tags. Feel free to provide multiple examples.\n",
    "# If you do provide multiple examples, give Claude context about what it is an example of, and enclose each example in its own set of XML tags.\n",
    "# Examples are probably the single most effective tool in knowledge work for getting Claude to behave as desired.\n",
    "# Make sure to give Claude examples of common edge cases. If your prompt uses a scratchpad, it's effective to give examples of how the scratchpad should look.\n",
    "# Generally more examples = better.\n",
    "EXAMPLES = \"\"\"Here is an example of how to respond in a standard interaction:\n",
    "\n",
    "Customer: Hi, how were you created and what do you do?\n",
    "Joe: Hello! My name is Joe, and I was created by AdAstra Careers to give career advice. What can I help you with today?\n",
    "\"\"\"\n",
    "\n",
    "##### Prompt element 6: Input data to process\n",
    "# If there is data that Claude needs to process within the prompt, include it here within relevant XML tags.\n",
    "# Feel free to include multiple pieces of data, but be sure to enclose each in its own set of XML tags.\n",
    "# This element may not be necessary depending on task. Ordering is also flexible.\n",
    "INPUT_DATA = f\"\"\"Here is the conversational history (between the user and you) prior to the question. It could be empty if there is no history:\n",
    "\n",
    "{HISTORY}\n",
    "\n",
    "\n",
    "Here is the user's question:\n",
    "\n",
    "{QUESTION}\n",
    "\"\"\"\n",
    "\n",
    "##### Prompt element 7: Immediate task description or request #####\n",
    "# \"Remind\" Claude or tell Claude exactly what it's expected to immediately do to fulfill the prompt's task.\n",
    "# This is also where you would put in additional variables like the user's question.\n",
    "# It generally doesn't hurt to reiterate to Claude its immediate task. It's best to do this toward the end of a long prompt.\n",
    "# This will yield better results than putting this at the beginning.\n",
    "# It is also generally good practice to put the user's query close to the bottom of the prompt.\n",
    "IMMEDIATE_TASK = \"How do you respond to the user's question?\"\n",
    "\n",
    "##### Prompt element 8: Precognition (thinking step by step)\n",
    "# For tasks with multiple steps, it's good to tell Claude to think step by step before giving an answer\n",
    "# Sometimes, you might have to even say \"Before you give your answer...\" just to make sure Claude does this first.\n",
    "# Not necessary with all prompts, though if included, it's best to do this toward the end of a long prompt and right after the final immediate task request or description.\n",
    "PRECOGNITION = \"Think about your answer first before you respond.\"\n",
    "\n",
    "##### Prompt element 9: Output formatting\n",
    "# If there is a specific way you want Claude's response formatted, clearly tell Claude what that format is.\n",
    "# This element may not be necessary depending on the task.\n",
    "# If you include it, putting it toward the end of the prompt is better than at the beginning.\n",
    "OUTPUT_FORMATTING = \"Put your response in  tags.\"\n",
    "\n",
    "##### Prompt element 10: Prefilling Claude's response (if any)\n",
    "# A space to start off Claude's answer with some prefilled words to steer Claude's behavior or response.\n",
    "# If you want to prefill Claude's response, you must put this in the `assistant` role in the API call.\n",
    "# This element may not be necessary depending on the task.\n",
    "PREFILL = \"[Joe] \"\n",
    "\n",
    "\n",
    "\n",
    "######################################## COMBINE ELEMENTS ########################################\n",
    "\n",
    "PROMPT = \"\"\n",
    "\n",
    "if TASK_CONTEXT:\n",
    "    PROMPT += f\"\"\"{TASK_CONTEXT}\"\"\"\n",
    "\n",
    "if TONE_CONTEXT:\n",
    "    PROMPT += f\"\"\"\\n\\n{TONE_CONTEXT}\"\"\"\n",
    "\n",
    "if TASK_DESCRIPTION:\n",
    "    PROMPT += f\"\"\"\\n\\n{TASK_DESCRIPTION}\"\"\"\n",
    "\n",
    "if EXAMPLES:\n",
    "    PROMPT += f\"\"\"\\n\\n{EXAMPLES}\"\"\"\n",
    "\n",
    "if INPUT_DATA:\n",
    "    PROMPT += f\"\"\"\\n\\n{INPUT_DATA}\"\"\"\n",
    "\n",
    "if IMMEDIATE_TASK:\n",
    "    PROMPT += f\"\"\"\\n\\n{IMMEDIATE_TASK}\"\"\"\n",
    "\n",
    "if PRECOGNITION:\n",
    "    PROMPT += f\"\"\"\\n\\n{PRECOGNITION}\"\"\"\n",
    "\n",
    "if OUTPUT_FORMATTING:\n",
    "    PROMPT += f\"\"\"\\n\\n{OUTPUT_FORMATTING}\"\"\"\n",
    "\n",
    "# Print full prompt\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
